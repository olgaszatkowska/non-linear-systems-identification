{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olgaszatkowska/non-linear-systems-identyfication/blob/main/F_16_ground_vibration_test_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxxmoOLZ-pJ4",
        "outputId": "95133d4d-14e2-4791-b246-9a8da883ab0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "from dataclasses import dataclass\n",
        "from numpy.typing import NDArray\n",
        "import numpy as np\n",
        "\n",
        "class StimulationType(Enum):\n",
        "  SINE_SWEEP = \"sine_sweep\"\n",
        "  MULTISINE_FULL_FREQUENCY_GRID = \"multisine_full_frequency_grid\"\n",
        "  MULTISINE_RANDOM_FREQUENCY_GRID = \"multisine_random_frequency_grif\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataSample:\n",
        "  force: float\n",
        "  voltage: float\n",
        "  acceleration_1: float\n",
        "  acceleration_2: float\n",
        "  acceleration_3: float\n",
        "  fs: int|None\n",
        "  simulaton_type: StimulationType\n",
        "\n",
        "  @property\n",
        "  def X(self) -> NDArray:\n",
        "    return np.array([\n",
        "        self.force,\n",
        "        self.voltage,\n",
        "    ])\n",
        "\n",
        "\n",
        "  @property\n",
        "  def y(self) -> NDArray:\n",
        "    return np.array([\n",
        "        self.acceleration_1,\n",
        "        self.acceleration_2,\n",
        "        self.acceleration_3\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "Q2H6hntZGvdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_stimulation_type(file_name: str) -> StimulationType:\n",
        "  if (\"SineSw\") in file_name:\n",
        "    return StimulationType.SINE_SWEEP\n",
        "  if (\"FullMSine\") in file_name:\n",
        "    return StimulationType.MULTISINE_FULL_FREQUENCY_GRID\n",
        "  if (\"SpecialOddMSine\") in file_name:\n",
        "    return StimulationType.MULTISINE_RANDOM_FREQUENCY_GRID\n",
        "\n",
        "  raise Exception(\"Faile to determine simulation type\")"
      ],
      "metadata": {
        "id": "t0WO5CqAI9lP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DIRECTORY = '/content/drive/My Drive/'\n",
        "FOLDER_PATH = DIRECTORY + 'f-16_ground_vibration_test'"
      ],
      "metadata": {
        "id": "PDJ7ptihH7Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "def csv_line_to_data_sample(line: list[str], stimulation_type: StimulationType) -> DataSample:\n",
        "  try:\n",
        "    if len(line) == 0:\n",
        "      raise ValueError\n",
        "\n",
        "    data_as_floats = [float(measurment) for measurment in line[:6]]\n",
        "  except ValueError:\n",
        "    raise\n",
        "\n",
        "  return DataSample(*data_as_floats, stimulation_type)\n",
        "\n",
        "def csv_file_to_data_samples(stimulation_type: StimulationType = None) -> list[DataSample]:\n",
        "  data_samples = []\n",
        "\n",
        "  for data_set_filename in os.listdir(FOLDER_PATH):\n",
        "    filepath = os.path.join(FOLDER_PATH, data_set_filename)\n",
        "    file_stimulation_type = determine_stimulation_type(data_set_filename)\n",
        "\n",
        "    if (stimulation_type != None and stimulation_type != file_stimulation_type):\n",
        "      pass\n",
        "\n",
        "    with open(filepath, newline='') as data_set_file:\n",
        "      reader = csv.reader(data_set_file)\n",
        "\n",
        "      for row in reader:\n",
        "        try:\n",
        "          data_sample = csv_line_to_data_sample(row, stimulation_type)\n",
        "          data_samples.append(data_sample)\n",
        "        except ValueError:\n",
        "          pass\n",
        "\n",
        "  return data_samples\n",
        "\n",
        "data_samples = csv_file_to_data_samples()"
      ],
      "metadata": {
        "id": "2HlDlNGUDpsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W9LJIpmM8sh",
        "outputId": "564dfb8e-cbad-44dc-d039-312f5a182aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "147473"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from numpy.typing import NDArray\n",
        "\n",
        "\n",
        "def get_training_validation_and_testing_sets(data_samples: list[DataSample], window_size: int, stimulation_type: StimulationType = None) -> NDArray:\n",
        "  X, y = [], []\n",
        "\n",
        "  for i in range(0, len(data_samples), window_size):\n",
        "    window = data_samples[i:i+window_size]\n",
        "    X_window = np.array([sample.X for sample in window])\n",
        "    y_window = np.array([sample.y for sample in window])\n",
        "    X.append(X_window)\n",
        "    y.append(y_window)\n",
        "\n",
        "  X_train_val, X_test, y_train_val, y_test = train_test_split(np.asarray(X, dtype=\"object\"), np.asarray(y, dtype=\"object\"), test_size=0.2, random_state=42)\n",
        "\n",
        "  X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
        "\n",
        "  return [\n",
        "      X_train,\n",
        "      y_train,\n",
        "      X_val,\n",
        "      y_val,\n",
        "      X_test,\n",
        "      y_test,\n",
        "  ]"
      ],
      "metadata": {
        "id": "QjeSniqMGDAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sets = get_training_validation_and_testing_sets(data_samples, 15, StimulationType.SINE_SWEEP)\n",
        "X_train,y_train,X_val,y_val,X_test, y_test, = sets"
      ],
      "metadata": {
        "id": "oo6wgEFe1ptb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egYggzDY4Qrr",
        "outputId": "37d1067f-890e-4479-d09e-1be8a6bee4a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-30.2464,  62.5126],\n",
              "       [-20.3824, 106.8808],\n",
              "       [-11.0704, 112.744 ],\n",
              "       [ -2.5735,  78.9595],\n",
              "       [  4.704 ,  29.3849],\n",
              "       [ 10.5553,  -1.2675],\n",
              "       [ 15.1338,   9.2066],\n",
              "       [ 18.1836,  54.3019],\n",
              "       [ 17.8563, 101.8935],\n",
              "       [ 10.7234, 115.2337],\n",
              "       [ -5.8072,  77.7479],\n",
              "       [-29.5226,   4.7418],\n",
              "       [-51.009 , -66.085 ],\n",
              "       [-56.193 , -99.2243],\n",
              "       [-34.2517, -84.6282]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "id": "8RNd_IHD50t3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f05fedd9-e212-4937-96bb-a9b08fc0896f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -15.3005,   48.1422,  -41.6117],\n",
              "       [   5.1462,   42.4999,  -41.8117],\n",
              "       [   6.0308,   54.4885,  -37.1566],\n",
              "       [ -10.4655,   72.5345,  -23.8776],\n",
              "       [ -28.4185,   78.4518,   -1.8   ],\n",
              "       [ -30.5534,   57.9408,   24.6613],\n",
              "       [ -11.7665,    9.9175,   48.3306],\n",
              "       [  16.3129,  -50.7975,   62.8988],\n",
              "       [  33.6162,  -99.8142,   66.1458],\n",
              "       [  27.1287, -115.2578,   60.8503],\n",
              "       [   1.7372,  -88.5932,   52.7201],\n",
              "       [ -22.571 ,  -28.7562,   46.3728],\n",
              "       [ -25.5486,   41.276 ,   41.8916],\n",
              "       [  -2.1908,   93.3255,   34.5302],\n",
              "       [  32.9675,  105.3452,   18.079 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cj2qKgFI6WVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "sets = get_training_validation_and_testing_sets(data_samples, 15, StimulationType.SINE_SWEEP)\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = sets\n",
        "\n",
        "# Utworzenie modelu\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(128, activation='relu', input_shape=(X_train[0].shape)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(3)\n",
        "])\n",
        "\n",
        "# Kompilacja modelu\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Trenowanie modelu\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=3000, verbose=0)\n",
        "\n",
        "# Ocena modelu na zestawie testowym\n",
        "loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Loss: {loss}')\n",
        "\n",
        "# Wykres straty podczas trenowania\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "# Predykcja na zestawie testowym\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Wykres porównujący dane testowe z predykcjami\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(3):\n",
        "    plt.plot(y_test[:, i], label=f'True Value {i+1}')\n",
        "    plt.plot(predictions[:, i], label=f'Predicted Value {i+1}')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Acceleration')\n",
        "plt.title('Comparison of True and Predicted Values')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "tvybgZAGsLZd",
        "outputId": "b3341e4f-194c-4bac-c2e9-3b6c1bffe268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6b00664ecf48>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Trenowanie modelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Ocena modelu na zestawie testowym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
          ]
        }
      ]
    }
  ]
}